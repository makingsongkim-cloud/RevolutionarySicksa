from fastapi import FastAPI, Request
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import uvicorn
import recommender
import os
import random
import asyncio
import time
import logging
from logging.handlers import RotatingFileHandler
from dotenv import load_dotenv
from session_manager import session_manager
from rate_limiter import rate_limiter
from datetime import datetime, timedelta

# ë‚ ì”¨ ìºì‹œ (10ë¶„ë§ˆë‹¤ ê°±ì‹ )
weather_cache = {
    "condition": None,
    "temp": None,
    "mapped_weather": None,
    "last_updated": None
}

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê¸°ë³¸ ë¡œê¹… ì„¤ì • (íŒŒì¼ + ì½˜ì†”)
LOG_PATH = os.path.join(os.path.dirname(__file__), "bot.log")
logger = logging.getLogger("lunch_bot")
logger.setLevel(logging.INFO)
logger.handlers.clear()

file_handler = RotatingFileHandler(
    LOG_PATH, maxBytes=5 * 1024 * 1024, backupCount=3, encoding="utf-8"
)
console_handler = logging.StreamHandler()
formatter = logging.Formatter("%(asctime)s %(levelname)s %(message)s")
file_handler.setFormatter(formatter)
console_handler.setFormatter(formatter)
logger.addHandler(file_handler)
logger.addHandler(console_handler)

app = FastAPI()

@app.get("/")
async def root():
    return {"status": "ok", "message": "DDMC Lunch Bot Server is running!"}

# Gemini API ì„¤ì • (ë©€í‹° í‚¤ ë¡œí…Œì´ì…˜ ì§€ì›)
GEMINI_FORCE_LOCAL = os.getenv("GEMINI_FORCE_LOCAL", "").lower() in ("1", "true", "yes", "y")
API_KEYS = [k.strip() for k in os.getenv("GEMINI_API_KEY", "").split(",") if k.strip()]
current_key_index = 0

gemini_model = None
intent_model = None
GEMINI_AVAILABLE = False

def reconfigure_gemini():
    global gemini_model, intent_model, GEMINI_AVAILABLE, current_key_index
    
    if not API_KEYS:
        GEMINI_AVAILABLE = False
        return False

    try:
        import google.generativeai as genai
        from google.generativeai.types import HarmCategory, HarmBlockThreshold
        
        target_key = API_KEYS[current_key_index]
        genai.configure(api_key=target_key)

        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }

        INTENT_CONFIG = {"temperature": 0.1, "max_output_tokens": 100, "top_p": 0.8, "top_k": 40}
        RESPONSE_CONFIG = {"temperature": 0.85, "max_output_tokens": 200, "top_p": 0.8, "top_k": 40}
        model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite")

        gemini_model = genai.GenerativeModel(model_name, safety_settings=safety_settings, generation_config=RESPONSE_CONFIG)
        intent_model = genai.GenerativeModel(model_name, safety_settings=safety_settings, generation_config=INTENT_CONFIG)
        
        GEMINI_AVAILABLE = True
        logger.info(f"âœ… Gemini API í‚¤ ì „í™˜ ì„±ê³µ! (Key Index: {current_key_index}, Model: {model_name})")
        return True
    except Exception as e:
        logger.error(f"âŒ Gemini API ì¬ì„¤ì • ì‹¤íŒ¨ (Index {current_key_index}): {e}")
        return False

if not GEMINI_FORCE_LOCAL and API_KEYS:
    reconfigure_gemini()
else:
    if GEMINI_FORCE_LOCAL:
        logger.warning("âš ï¸ Gemini API ê°•ì œ ë¹„í™œì„±í™” ëª¨ë“œì…ë‹ˆë‹¤.")
    else:
        logger.warning("âš ï¸ ë“±ë¡ëœ GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

# í‚¤ì›Œë“œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ (Fallbackìš©)
CUISINE_KEYWORDS = {
    "í•œì‹": ["í•œì‹", "í•œêµ­", "ê¹€ì¹˜", "ëœì¥", "ë¹„ë¹”ë°¥", "êµ­ë°¥", "ì°Œê°œ"],
    "ì¤‘ì‹": ["ì¤‘ì‹", "ì¤‘êµ­", "ì§œì¥", "ì§¬ë½•", "íƒ•ìˆ˜ìœ¡", "ë§ˆë¼"],
    "ì¼ì‹": ["ì¼ì‹", "ì¼ë³¸", "ì´ˆë°¥", "ë¼ë©˜", "ëˆê¹ŒìŠ¤", "ìš°ë™"],
    "ì–‘ì‹": ["ì–‘ì‹", "ì„œì–‘", "íŒŒìŠ¤íƒ€", "ìŠ¤í…Œì´í¬", "í”¼ì", "í–„ë²„ê±°"],
    "ë¶„ì‹": ["ë¶„ì‹", "ë–¡ë³¶ì´", "ê¹€ë°¥", "ë¼ë©´", "ìˆœëŒ€"]
}

WEATHER_KEYWORDS = {
    "ë¹„": ["ë¹„", "ìš°ì‚°", "ì¥ë§ˆ", "ë¹„ì˜¤", "ë¹—"],
    "ëˆˆ": ["ëˆˆ", "í•¨ë°•ëˆˆ", "ëˆˆì˜¤", "ëˆˆì´"],
    "ë”ìœ„": ["ë”ì›Œ", "ë¥", "ì—¬ë¦„", "ë¬´ë”ìœ„", "ë”ìš´"],
    "ì¶”ìœ„": ["ì¶”ì›Œ", "ì¶¥", "ê²¨ìš¸", "ìŒ€ìŒ€"],
    "í•œíŒŒ": ["í•œíŒŒ", "ê°œì¶¥", "ë„ˆë¬´ì¶¥", "ì–¼ì–´", "ì˜í•˜"]
}

MOOD_KEYWORDS = {
    "í™”ë‚¨": [
        "í™”ë‚˜", "í™”ë‚œ", "í™”ë‚¬", "í™”ë‚˜ë‹¤", "í™”ë‚œë‹¤", "ì§œì¦", "ì—´ë°›", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë§¤ìš´", "ë¹¡ì³", "ë¹¡ì¹˜", "ë¹¡ì¹˜ë„¤", "ë¹¡ì¹œë‹¤",
        "ì¢†", "ì¢†ê°™", "ì”¨ë°œ", "ì‹œë°œ", "ê°œê°™", "ê°œìƒˆ", "ì—¿", "ì—¿ë¨¹",
        "ì¡´ë‚˜", "ê°œì§œì¦", "ì—´ë¶ˆ", "ìŠ¹ì§ˆ", "ë¯¸ì¹˜ê² ",
        "ê±°ì§€ê°™", "ê·¸ì§€ê°™", "ê±°ì§€ ê°™ë‹¤", "ê·¸ì§€ ê°™ë‹¤", "ë”ëŸ½"
    ],
    "í–‰ë³µ": ["í–‰ë³µ", "ê¸°ë¶„ì¢‹", "ì‹ ë‚˜", "ì¦ê±°", "ì›”ê¸‰"],
    "ìš°ìš¸": ["ìš°ìš¸", "ìŠ¬í¼", "ê¿€ê¿€", "ë‹¤ìš´"],
    "í”¼ê³¤": ["í”¼ê³¤", "ì§€ì³", "í˜ë“¤", "ë…¹ì´ˆ", "íƒˆì§„", "ê¸°ìš´ì—†", "ì§€ì¹¨"],
    "ì¡¸ë¦¼": ["ì¡¸ë ¤", "ì¡¸ë¦¼", "ì ì™€", "ì ì˜´", "ê¾¸ë²…", "í•˜í’ˆ"],
    "ë°°ê³ í””": ["ë°°ê³ íŒŒ", "ë°°ê³ í””", "í—ˆê¸°", "êµ¶ì£¼", "ë°°ê¼½ì‹œê³„", "ì‹œì¥"],
    "ì™¸ë¡œì›€": ["ì™¸ë¡œ", "ì“¸ì“¸", "ì‹¬ì‹¬", "í˜¼ì", "ê³ ë…"],
    "í”Œë ‰ìŠ¤": ["ë¹„ì‹¼", "ê³ ê¸‰", "ë²•ì¹´", "í”Œë ‰ìŠ¤", "ì›”ê¸‰", "ë³´ë„ˆìŠ¤", "ëˆì§€ë„"],
    "ë‹¤ì´ì–´íŠ¸": ["ë‹¤ì´ì–´íŠ¸", "ì‚´ë¹¼", "ê°€ë²¼ìš´", "ìƒëŸ¬ë“œ", "ê´€ë¦¬", "ì‹ë‹¨"]
}

# [ê³µìš© ê°ì²´] ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ìƒì„±í•˜ì—¬ I/O ë¶€í•˜ ê°ì†Œ
r = recommender.LunchRecommender()

# Input Models for Kakao Skill Payload
class Action(BaseModel):
    params: Dict[str, Any] = {}

class User(BaseModel):
    id: str

class UserRequest(BaseModel):
    utterance: str
    user: Optional[User] = None

class SkillPayload(BaseModel):
    userRequest: UserRequest
    action: Action = Action()


def get_josa(word: str, particle_type: str) -> str:
    """
    í•œê¸€ ë‹¨ì–´ì˜ ë°›ì¹¨ ìœ ë¬´ì— ë”°ë¼ ì ì ˆí•œ ì¡°ì‚¬ë¥¼ ë¶™ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    particle_type: "ì€/ëŠ”", "ì´/ê°€", "ì„/ë¥¼", "ì™€/ê³¼"
    """
    if not word:
        return ""
        
    last_char = word[-1]
    # í•œê¸€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„: 0xAC00 ~ 0xD7A3
    if not (0xAC00 <= ord(last_char) <= 0xD7A3):
        # í•œê¸€ì´ ì•„ë‹ˆë©´ ê¸°ë³¸ê°’(ì•ìª½ ì¡°ì‚¬) ë°˜í™˜ (ì˜ˆ: PizzaëŠ”)
        return f"{word}{particle_type.split('/')[0]}"
    
    # ë°›ì¹¨ ìœ ë¬´ í™•ì¸ ((ìœ ë‹ˆì½”ë“œ - 0xAC00) % 28 > 0 ì´ë©´ ë°›ì¹¨ ìˆìŒ)
    has_batchim = (ord(last_char) - 0xAC00) % 28 > 0
    
    particles = particle_type.split('/')
    if has_batchim:
        return f"{word}{particles[0]}" # ì€, ì´, ì„, ê³¼
    else:
        return f"{word}{particles[1]}" # ëŠ”, ê°€, ë¥¼, ì™€


import asyncio
INTENT_TIMEOUT_SEC = 1.8
GENERATION_TIMEOUT_SEC = 2.5

# [ìµœì í™”] ì§€ìˆ˜ ë°±ì˜¤í”„ ê¸°ë°˜ ì¿¨ë‹¤ìš´ ì‹œìŠ¤í…œ
GEMINI_INITIAL_COOLDOWN = 30.0 # ì´ˆê¸° ì¿¨ë‹¤ìš´ 30ì´ˆ
GEMINI_MAX_COOLDOWN = 600.0    # ìµœëŒ€ ì¿¨ë‹¤ìš´ 10ë¶„
GEMINI_BACKOFF_FACTOR = 2.0    # ë°°ìˆ˜
GEMINI_COOLDOWN_UNTIL = 0.0
current_gemini_cooldown_sec = GEMINI_INITIAL_COOLDOWN


def _is_rate_limited_error(err: Exception) -> bool:
    msg = str(err).lower()
    return "429" in msg or "quota" in msg or "rate limit" in msg


def _gemini_in_cooldown() -> bool:
    return time.time() < GEMINI_COOLDOWN_UNTIL


def _set_gemini_cooldown() -> None:
    global GEMINI_COOLDOWN_UNTIL, current_gemini_cooldown_sec, current_key_index
    
    # [ë©€í‹° í‚¤] 429 ì—ëŸ¬ ë°œìƒ ì‹œ ì¦‰ì‹œ ë‹¤ìŒ í‚¤ë¡œ ì „í™˜ ì‹œë„
    if len(API_KEYS) > 1:
        old_idx = current_key_index
        current_key_index = (current_key_index + 1) % len(API_KEYS)
        logger.warning(f"ğŸ”„ Rate Limit ê°ì§€! í‚¤ ì „í™˜ ì‹œë„: Index {old_idx} -> {current_key_index}")
        if reconfigure_gemini():
            # í‚¤ ì „í™˜ ì„±ê³µ ì‹œ ì¿¨ë‹¤ìš´ ì—†ì´ ì¦‰ì‹œ ì¬ì‹œë„ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì • (ë‹¨, ë°±ì˜¤í”„ëŠ” ìœ ì§€í•˜ì—¬ ì•ˆì „ì„± í™•ë³´)
            GEMINI_COOLDOWN_UNTIL = 0
            return

    GEMINI_COOLDOWN_UNTIL = time.time() + current_gemini_cooldown_sec
    logger.warning(f"âš ï¸ ëª¨ë“  í‚¤ í•œë„ ì´ˆê³¼ ë˜ëŠ” ë‹¨ì¼ í‚¤ ì¿¨ë‹¤ìš´ ì§„ì…: {current_gemini_cooldown_sec:.1f}ì´ˆ")
    current_gemini_cooldown_sec = min(GEMINI_MAX_COOLDOWN, current_gemini_cooldown_sec * GEMINI_BACKOFF_FACTOR)

def _reset_gemini_backoff() -> None:
    """ì„±ê³µ ì‹œ ë°±ì˜¤í”„ ì´ˆê¸°í™”"""
    global current_gemini_cooldown_sec
    if current_gemini_cooldown_sec > GEMINI_INITIAL_COOLDOWN:
        current_gemini_cooldown_sec = GEMINI_INITIAL_COOLDOWN
        logger.info("âœ… Gemini ë°±ì˜¤í”„ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

async def run_gemini_with_timeout(model, prompt: str, timeout_sec: float, log_label: str):
    """Execute Gemini call with a strict timeout and return text or None."""
    if _gemini_in_cooldown():
        remaining = GEMINI_COOLDOWN_UNTIL - time.time()
        logger.warning(f"{log_label} skipped: Gemini in cooldown ({remaining:.1f}s left)")
        return None
    try:
        # ê°€ê¸‰ì  ìì²´ ë¹„ë™ê¸° ë©”ì„œë“œ ì‚¬ìš©
        response = await asyncio.wait_for(model.generate_content_async(prompt), timeout=timeout_sec)
        result = (response.text or "").strip()
        if result:
            _reset_gemini_backoff() # ì„±ê³µí•˜ë©´ ë°±ì˜¤í”„ ì´ˆê¸°í™”
        return result
    except asyncio.TimeoutError:
        logger.warning(f"{log_label} timeout after {timeout_sec}s")
    except Exception as e:
        if _is_rate_limited_error(e):
            _set_gemini_cooldown()
            logger.warning(f"{log_label} rate-limited; entering cooldown")
        logger.warning(f"{log_label} fail: {e}")
    return None

def format_history(conversation_history: List[Dict], limit: int = 2) -> str:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ… (í† í° ì ˆì•½)"""
    if not conversation_history:
        return ""
    return "\n".join([
        f"{h['role']}: {h['message']}"
        for h in conversation_history[-limit:]
    ])
def get_meal_label(now: Optional[datetime] = None) -> str:
    """í˜„ì¬ ì‹œê°„ ê¸°ì¤€ ì¶”ì²œ ì‹ì‚¬ ë¼ë²¨ ë°˜í™˜."""
    current = now or datetime.now()
    hour = current.hour
    # 10ì‹œ~10:59: ì•„ì¹¨
    if 10 <= hour < 11:
        return "ì•„ì¹¨"
    # 11ì‹œ~18ì‹œ: ì ì‹¬
    if 11 <= hour < 18:
        return "ì ì‹¬"
    # 18ì‹œ~20ì‹œ: ì €ë…
    if 18 <= hour < 20:
        return "ì €ë…"
    # ê¸°íƒ€ ì‹œê°„: ì•„ì¹¨(10ì‹œ ì´ì „) / ì €ë…(20ì‹œ ì´í›„)
    return "ì•„ì¹¨" if hour < 10 else "ì €ë…"


def get_requested_meal_label(utterance: str) -> Optional[str]:
    """ì‚¬ìš©ì ë°œí™”ì—ì„œ ëª…ì‹œëœ ì‹ì‚¬ ë¼ë²¨ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not utterance:
        return None
    candidates = {
        "ì•„ì¹¨": ["ì•„ì¹¨"],
        "ì ì‹¬": ["ì ì‹¬"],
        "ì €ë…": ["ì €ë…"],
    }
    utter = utterance.replace(" ", "")
    earliest = None
    for label, keywords in candidates.items():
        for kw in keywords:
            idx = utter.find(kw)
            if idx != -1 and (earliest is None or idx < earliest[0]):
                earliest = (idx, label)
    return earliest[1] if earliest else None


def get_time_context(utterance: str) -> Dict[str, Optional[str]]:
    """í˜„ì¬/ìš”ì²­ ì‹ì‚¬ ë¼ë²¨ ë° ëŠ¦ì€ ì €ë… ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    now = datetime.now()
    current_label = get_meal_label(now)
    requested_label = get_requested_meal_label(utterance)
    is_late_evening = current_label == "ì €ë…" and now.hour >= 20
    return {
        "current_label": current_label,
        "requested_label": requested_label,
        "is_late_evening": is_late_evening,
    }


def contains_explain_keyword(utterance: str) -> bool:
    """ì´ìœ /ì™œ ì§ˆë¬¸ ì—¬ë¶€ë¥¼ ê°„ë‹¨íˆ íŒë‹¨í•©ë‹ˆë‹¤."""
    if not utterance:
        return False
    text = utterance.lower()
    return any(k in text for k in ["ì™œ", "ì´ìœ ", "why", "ì–´ì§¸ì„œ", "ì´ìœ ëŠ”"])

async def analyze_intent_with_gemini(utterance: str, conversation_history: List[Dict]) -> Dict[str, Any]:
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. (Short Prompt + Strict Config)"""
    if _gemini_in_cooldown():
        return analyze_intent_fallback(utterance)
    try:
        history_text = format_history(conversation_history, limit=2)
        
        from datetime import datetime
        now_str = datetime.now().strftime("%I:%M%p") # ì‹œê°„ í¬ë§· ë‹¨ì¶•

        prompt = f"""ì˜ë„ ë¶„ì„ (JSON):
íˆìŠ¤í† ë¦¬:
{history_text}
ì…ë ¥: "{utterance}" ({now_str})

ë¶„ë¥˜:
1. intent: recommend (ë©”ë‰´ì¶”ì²œìš”ì²­), explain (ì´ìœ ), reject (ê±°ì ˆ), accept (ìˆ˜ë½), casual (ì¡ë‹´/ì¼ë°˜ì§ˆë¬¸), help (ë„ì›€)
2. casual_type: greeting, thanks, chitchat (casualì¼ë•Œ)
3. emotion: negative, neutral, positive
4. filter: [í•œì‹, ì¤‘ì‹, ì¼ì‹, ì–‘ì‹, ë¶„ì‹]
5. weather: ë¹„, ëˆˆ, ë”ìœ„, ì¶”ìœ„, í•œíŒŒ
6. mood: í”¼ê³¤, í–‰ë³µ, ìš°ìš¸, í™”ë‚¨, ë‹¤ì´ì–´íŠ¸, í”Œë ‰ìŠ¤

JSONë§Œ ì¶œë ¥:"""

        # íƒ€ì„ì•„ì›ƒ ì§§ê²Œ(ì‘ë‹µì„± ìš°ì„ )
        response = await asyncio.wait_for(intent_model.generate_content_async(prompt), timeout=INTENT_TIMEOUT_SEC)
        result_text = response.text.strip()
        
        # JSON íŒŒì‹± cleanup
        if "```" in result_text:
            result_text = result_text.replace("```json", "").replace("```", "").strip()
            
        import json
        result = json.loads(result_text)
        
        # í‚¤ ì´ë¦„ í˜¸í™˜ì„± (filter -> cuisine_filters)
        if 'filter' in result:
            result['cuisine_filters'] = result.pop('filter')
            
        return result
        
    except (asyncio.TimeoutError, Exception) as e:
        if _is_rate_limited_error(e):
            _set_gemini_cooldown()
            logger.warning("âš ï¸ Intent ë¶„ì„ rate-limited; entering cooldown")
        logger.warning(f"âš ï¸ Intent ë¶„ì„ ì‹¤íŒ¨/íƒ€ì„ì•„ì›ƒ: {e}")
        return analyze_intent_fallback(utterance)


def analyze_intent_fallback(utterance: str) -> Dict[str, Any]:
    """
    í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (Fallback).
    """
    utterance_lower = utterance.lower()
    
    # ì˜ë„ ë¶„ì„
    intent = "casual"  # ê¸°ë³¸ê°’ ë³€ê²½: recommend -> casual (ì•„ë¬´ ë§ì´ë‚˜ í•˜ë©´ ì¡ë‹´ìœ¼ë¡œ ì²˜ë¦¬)
    casual_type = "chitchat"
    
    # ì¼ìƒ ëŒ€í™” íŒ¨í„´ (ëª…í™•í•œ ì¸ì‚¬/ê°ì‚¬ ë“±)
    if any(word in utterance_lower for word in ["ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”", "í•˜ì´", "ã…ã…‡", "hello", "hi", "í—¬ë¡œ", "í—¬ë¡œìš°", "ë°˜ê°€", "ë°˜ê°€ì›Œ", "ì—¬ë³´ì„¸ìš”", "ëˆ„êµ¬", "ë„Œëˆ„êµ¬", "ì´ë¦„ì´", "ë´‡ì´ë¦„"]):
        intent = "casual"
        casual_type = "greeting"
    elif any(word in utterance_lower for word in ["ê³ ë§ˆ", "ê°ì‚¬", "thanks", "thank", "ã…‡ã…‹", "ì•Œì•˜ì–´", "ã„±ã……", "ã„³"]):
        intent = "casual"
        casual_type = "thanks"
    elif any(word in utterance_lower for word in ["ì™œ", "ì´ìœ ", "why", "ì–´ì§¸ì„œ", "ì´ìœ ëŠ”", "ì„¤ëª…í•´", "ì™œì£ "]):
        # [CRITICAL] ì„¤ëª… ìš”ì²­ì€ ìµœìš°ì„ ìˆœìœ„ë¡œ ì²˜ë¦¬í•˜ê³  ì¦‰ì‹œ ë°˜í™˜ (ì˜¤ë²„ë¼ì´ë“œ ë°©ì§€)
        return {"intent": "explain", "casual_type": None, "emotion": "neutral", "cuisine_filters": [], "weather": None, "mood": None, "tag_filters": []}
    elif any(word in utterance_lower for word in ["ì‹«", "ë³„ë¡œ", "ë‹¤ë¥¸", "ì•„ë‹ˆ", "no", "íŒ¨ìŠ¤", "ë°”ê¿”", "ë§ê³ ", "ë‹´ì—", "ë‚˜ì¤‘ì—"]):
        intent = "reject"
    # recommend (ëª…í™•í•œ í‚¤ì›Œë“œê°€ ìˆì„ ë•Œë§Œ ì¶”ì²œ)
    elif any(word in utterance_lower for word in ["ì¶”ì²œ", "ë©”ë‰´", "ë°¥", "ì‹ì‚¬", "ë°°ê³ íŒŒ", "ë­ë¨¹ì§€", "ê³¨ë¼ì¤˜", "ì•„ë¬´ê±°ë‚˜", "ëœë¤", "ì•Œì•„ì„œ", "í•´ë´", "í•´", "ê³ ", "ë°°ê³±", "ì¶œì¶œ", "í—ˆê¸°"]):
        intent = "recommend"
    # accept (ì§§ì€ ê¸ì •)
    elif any(word in utterance_lower for word in ["ì‘", "ã…‡ã…‡", "ã…‡ã…‹", "ì¢‹ì•„", "ì½œ", "ê³ ê³ "]):
        intent = "accept"
    # help (ë„ì›€ë§)
    elif any(word in utterance_lower for word in ["ë„ì›€", "ì‚¬ìš©ë²•", "ì„¤ëª…", "help", "ì–´ë–»ê²Œ", "ê¸°ëŠ¥"]):
        intent = "help"
    # ê¸ì • í”¼ë“œë°± íŒ¨í„´
    elif any(word in utterance_lower for word in ["ì¢‹", "ë§›ìˆ", "ê±°ê¸°", "ê·¸ê±°", "ë¨¹ì„", "ok", "yes", "êµ¿"]):
        intent = "accept"
    
    # ì§ˆë¬¸í˜• ì–´ë¯¸ ì²´í¬ (ë³´ê°•)
    if any(utterance_lower.endswith(ending) for ending in ["?", "ëƒ", "ê¹Œ", "ë‹ˆ", "ìš”", "ì£ ", "ê°€", "ë‚˜"]):
        # ì¶”ì²œ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì¡ë‹´ ìœ ì§€
        if intent == "recommend" and not any(word in utterance_lower for word in ["ì¶”ì²œ", "ë©”ë‰´", "ì ì‹¬", "ë°¥"]):
             intent = "casual"
             casual_type = "chitchat"
    
    # ê°ì • ë¶„ì„
    emotion = "neutral"
    if any(word in utterance_lower for word in ["ì¢†ê°™", "ì§œì¦", "ì—´ë°›", "í™”ë‚˜", "í˜ë“¤", "ìš°ìš¸"]):
        emotion = "negative"
    elif any(word in utterance_lower for word in ["í–‰ë³µ", "ì¢‹", "ì‹ ë‚˜", "ì¦ê±°"]):
        emotion = "positive"
    
    # ìŒì‹ ì¢…ë¥˜ ì¶”ì¶œ
    cuisine_filters = []
    for cuisine, keywords in CUISINE_KEYWORDS.items():
        if any(keyword in utterance_lower for keyword in keywords):
            cuisine_filters.append(cuisine)
            
    # [NEW] ìŒì‹ íƒœê·¸ ì¶”ì¶œ (êµ­ë¬¼, ë©´, ê³ ê¸° ë“±) -> search_filtersë¡œ í™œìš©
    # CUISINE_KEYWORDSì— ì—†ëŠ” 'íŠ¹ì§•' ê¸°ë°˜ í‚¤ì›Œë“œ
    tag_keywords_map = {
        "soup": ["êµ­ë¬¼", "ì°Œê°œ", "íƒ•", "ì „ê³¨", "êµ­ë°¥"],
        "noodle": ["ë©´", "êµ­ìˆ˜", "ìš°ë™", "ë¼ë©´", "ì§¬ë½•", "ì§œì¥", "íŒŒìŠ¤íƒ€", "ì†Œë°”"],
        "meat": ["ê³ ê¸°", "ìœ¡ë¥˜", "ëˆê¹ŒìŠ¤", "ìŠ¤í…Œì´í¬", "ê°ˆë¹„", "ë¶ˆê³ ê¸°", "ì œìœ¡"],
        "rice": ["ë°¥", "ë®ë°¥", "ë³¶ìŒë°¥", "ë¹„ë¹”ë°¥", "ë¦¬ì¡°ë˜"],
        "spicy": ["ë§¤ìš´", "ë¹¨ê°„", "ì–¼í°", "ì¹¼ì¹¼"],
        "light": ["ê°€ë²¼ìš´", "ìƒëŸ¬ë“œ", "ìƒŒë“œìœ„ì¹˜", "ë‹¤ì´ì–´íŠ¸"],
        "heavy": ["ë“ ë“ ", "í‘¸ì§", "í•´ì¥"]
    }
    
    tag_filters = []
    for tag, keywords in tag_keywords_map.items():
        if any(keyword in utterance_lower for keyword in keywords):
            tag_filters.append(tag)
            
    # ë‚ ì”¨ ì¶”ì¶œ
    weather = None
    for weather_type, keywords in WEATHER_KEYWORDS.items():
        if any(keyword in utterance_lower for keyword in keywords):
            weather = weather_type
            break
    
    # ê¸°ë¶„ ì¶”ì¶œ
    mood = None
    for mood_type, keywords in MOOD_KEYWORDS.items():
        if any(keyword in utterance_lower for keyword in keywords):
            mood = mood_type
            break
    # [NEW] ìŒì‹ í‚¤ì›Œë“œ, ê¸°ë¶„, ë‚ ì”¨ ì¤‘ í•˜ë‚˜ë¼ë„ ë°œê²¬ë˜ë©´ ì¶”ì²œ Intentë¡œ ìœ ë„
    if (cuisine_filters or tag_filters or mood or weather) and intent == "casual":
        intent = "recommend"

    return {
        "intent": intent,
        "casual_type": casual_type,
        "emotion": emotion,
        "cuisine_filters": cuisine_filters,
        "weather": weather,
        "mood": mood,
        "tag_filters": tag_filters # [NEW] íƒœê·¸ í•„í„° ì¶”ê°€
    }


def generate_explanation_fallback(rec: Dict, weather: Optional[str] = None, mood: Optional[str] = None) -> str:
    """
    ë©”ë‰´ ì¶”ì²œ ì´ìœ ë¥¼ ë¡œì»¬ì—ì„œ ìƒì„± (Fallback)
    - ë‹¨ìˆœ í…œí”Œë¦¿ ì¡°í•©ì´ì§€ë§Œ, íƒœê·¸/ë‚ ì”¨/ê¸°ë¶„ì„ ë°˜ì˜í•˜ì—¬ ê·¸ëŸ´ì‹¸í•˜ê²Œ ë§Œë“¦
    """
    name = rec.get('name', 'ì´ ë©”ë‰´')
    category = rec.get('category', 'ìŒì‹')
    tags = rec.get('tags', [])
    
    # 1. íƒœê·¸ ê¸°ë°˜ ë…¼ë¦¬
    reason_logic = f"**{category}** ë©”ë‰´ë¡œ ìœ ëª…í•œ ê³³ì´ì—ìš”."
    
    if "spicy" in tags:
        reason_logic = "ìŠ¤íŠ¸ë ˆìŠ¤ í™• í’€ë¦¬ëŠ” ë§¤ì½¤í•œ ë§›ì´ ì¼í’ˆì´ê±°ë“ ìš”! ğŸ”¥"
    elif "soup" in tags:
        if weather and weather in ["ë¹„", "ëˆˆ", "íë¦¼", "ì¶”ìœ„", "ì¥ë§ˆ"]:
            reason_logic = "ì˜¤ëŠ˜ì²˜ëŸ¼ ìŒ€ìŒ€í•œ ë‚ ì”¨ì—” ì´ëŸ° ëœ¨ëˆí•œ êµ­ë¬¼ì´ ìµœê³ ì–ì•„ìš”. ğŸ²"
        else:
            reason_logic = "ì†ì´ í™• í’€ë¦¬ëŠ” êµ­ë¬¼ ë§›ì´ ëë‚´ì£¼ê±°ë“ ìš”."
    elif "meat" in tags:
        if mood == "ìš°ìš¸" or mood == "í™”ë‚¨":
            reason_logic = "ê¸°ë¶„ì´ ì €ê¸°ì••ì¼ ë• ì—­ì‹œ ê³ ê¸° ì•ìœ¼ë¡œ ê°€ì•¼ì£ ! ğŸ–"
        else:
            reason_logic = "ë“ ë“ í•˜ê²Œ ë°° ì±„ìš°ê¸°ì—” ê³ ê¸°ê°€ ë”±ì´ë‹ˆê¹Œìš”."
    elif "light" in tags:
        if mood == "ë‹¤ì´ì–´íŠ¸":
             reason_logic = "ê°€ë³ê²Œ ê´€ë¦¬í•˜ê¸° ë”± ì¢‹ì€ ë©”ë‰´ë¼ ê³¨ëì–´ìš”. ğŸ¥—"
        else:
             reason_logic = "ë”ë¶€ë£©í•˜ì§€ ì•Šê³  ê¹”ë”í•˜ê²Œ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ë©”ë‰´ì˜ˆìš”. ğŸ¥—"
    elif "noodle" in tags:
        reason_logic = "í›„ë£¨ë£© ë©´ì¹˜ê¸° í•˜ê¸° ë”± ì¢‹ì€ ë‚ ì´ë‹ˆê¹Œìš”! ğŸœ"

    # 2. ë‚ ì”¨/ê¸°ë¶„ ì¶”ê°€ ë©˜íŠ¸
    extra = ""
    if weather:
        weather_notes = {
            "ë¹„": "ë¹„ê°€ ì™€ì„œ ë”°ëœ»í•˜ê³  ë“ ë“ í•œ ë©”ë‰´ê°€ ì˜ ì–´ìš¸ë ¤ìš”. â˜”",
            "ëˆˆ": "ì¶”ìš´ ë‚ ì”¨ì—” ë”°ëœ»í•œ ë©”ë‰´ê°€ ë”±ì´ì—ìš”. â„ï¸",
            "íë¦¼": "ìŒ€ìŒ€í•  ìˆ˜ ìˆìœ¼ë‹ˆ ì† í¸í•œ ë©”ë‰´ë¥¼ ê³¨ëì–´ìš”. â˜ï¸",
            "ë”ìœ„": "ë”ìš´ ë‚ ì”¨ì—” ë„ˆë¬´ ë¬´ê±°ìš´ ë©”ë‰´ëŠ” í”¼í•˜ëŠ” ê²Œ ì¢‹ì•„ìš”. â˜€ï¸",
            "ì¶”ìœ„": "ì¶”ìš¸ ë• ëœ¨ëˆí•œ ë©”ë‰´ê°€ ìµœê³ ì£ . ğŸ¥¶",
            "í•œíŒŒ": "í•œíŒŒì—” ë”°ëœ»í•˜ê²Œ ë“ ë“ í•˜ê²Œ ë¨¹ëŠ” ê²Œ ì¢‹ì•„ìš”. ğŸ§Š",
            "ë§‘ìŒ": "ë§‘ì€ ë‚ ì—” ê°€ë³ê²Œ ì¦ê¸°ê¸° ì¢‹ì€ ë©”ë‰´ë¥¼ ê³¨ëì–´ìš”. ğŸŒ¤ï¸",
        }
        extra = f"\n\n(ì°¸ê³ : {weather_notes.get(weather, 'ë‚ ì”¨ì— ë§ì¶° ë¬´ë‚œí•œ ë©”ë‰´ë¡œ ê³¨ëì–´ìš”.')})"
    
    # 3. ë§ˆë¬´ë¦¬ (ë‹¤ì–‘ì„±)
    import random
    closers = [
        "ë¶„ëª… ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì‹ì‚¬ê°€ ë˜ì‹¤ ê±°ì˜ˆìš”! ğŸ˜Š",
        "í•œ ë²ˆ ë“œì…”ë³´ì‹œë©´ ì œ ë§ˆìŒì„ ì•„ì‹¤ ê±°ì˜ˆìš”!",
        "ë§ˆìŠ¤í„°ë‹˜ ì…ë§›ì—ë„ ë”± ë§ì„ ê±°ë¼ê³  í™•ì‹ í•´ìš”. âœ¨",
        "í›„íšŒ ì—†ìœ¼ì‹¤ ì„ íƒì´ ë  ê±°ì˜ˆìš”. ğŸ‘",
        "ì œê°€ ê°•ë ¥ ì¶”ì²œí•˜ëŠ” ì´ìœ ëë‹ˆë‹¤! ğŸ‘"
    ]
    
    return f"'{name}'(ì„)ë¥¼ ì¶”ì²œí•œ ì´ìœ ìš”?\n\n{reason_logic}{extra}\n\n{random.choice(closers)}"


async def generate_casual_response_with_gemini(
    utterance: str,
    casual_type: str,
    conversation_history: List[Dict],
    user_id: str = "Master",
    meal_label: str = "ì ì‹¬",
) -> str:
    """ì¼ìƒ ëŒ€í™” ì‘ë‹µ (Short Prompt)"""
    history_text = format_history(conversation_history)
    
    prompt = f"""ì¹œê·¼í•œ ì±—ë´‡ ì‘ë‹µ:
íˆìŠ¤í† ë¦¬:
{history_text}
ì‚¬ìš©ì: {utterance}
í˜„ì¬ ì¶”ì²œ ì‹ì‚¬: {meal_label}

ê°€ì´ë“œ:
1. ì¹œêµ¬ì²˜ëŸ¼ ë°ê³  ê³µê°í•˜ëŠ” ë§íˆ¬ (ì´ëª¨ì§€ ì‚¬ìš©)
2. ì‚¬ìš©ìì˜ ë§ì— ë§ì¶° ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µ (ì–µì§€ë¡œ ì ì‹¬ ì–˜ê¸° êº¼ë‚´ì§€ ë§ ê²ƒ)
3. ì¸ì‚¬ì¸ ê²½ìš°ì—ëŠ” ì¸ì‚¬í•˜ê³  ë©”ë‰´ ì¶”ì²œ ë°›ì„ì§€ ì§ˆë¬¸
4. ë§Œì•½ ì‚¬ìš©ìê°€ ë°°ê³ íŒŒí•˜ê±°ë‚˜ ì ì‹¬ ë§¥ë½ì¼ ë•Œë§Œ ë©”ë‰´ ì¶”ì²œ ìœ ë„
5. 1-2ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ

ì‘ë‹µ:"""
    
    response_text = await run_gemini_with_timeout(
        gemini_model, prompt, GENERATION_TIMEOUT_SEC, "Casual response"
    )
    if response_text:
        return response_text
    return generate_casual_response_fallback(casual_type, user_id, meal_label=meal_label)


def generate_casual_response_fallback(casual_type: str, user_id: str = "Master", meal_label: str = "ì ì‹¬") -> str:
    """
    ì¼ìƒ ëŒ€í™” ê¸°ë³¸ ì‘ë‹µ (Fallback)
    """
    if casual_type == "greeting":
        return f"ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š {meal_label} ì¶”ì²œ ë°›ì•„ë³´ì‹¤ë˜ìš”?"
    elif casual_type == "thanks":
        return f"ì²œë§Œì—ìš”! ë§›ìˆê²Œ ë“œì„¸ìš”~ ğŸ½ï¸ ë‹¤ìŒì—ë„ {meal_label} ê³ ë¯¼ë˜ì‹œë©´ ì–¸ì œë“  ë¶ˆëŸ¬ì£¼ì„¸ìš”!"
    else:
        # ì•¼, ë“± ì§§ì€ í˜¸ì¶œì´ë‚˜ ì¡ë‹´ì— ëŒ€í•œ ëŒ€ì‘
        messages = [
            f"ë„¤! {meal_label} ë©”ë‰´ ê³ ë¯¼ì´ì‹ ê°€ìš”? ğŸ¤”",
            f"ë¶€ë¥´ì…¨ë‚˜ìš”? ë§›ìˆëŠ” {meal_label} ì¶”ì²œí•´ë“œë¦´ê¹Œìš”? ğŸ˜‹",
            f"ì‹¬ì‹¬í•˜ì‹ ê°€ìš”? ì €ë‘ {meal_label} ë©”ë‰´ ê³ ë¥´ê¸° í•´ìš”! ğŸ²",
            f"ë„¤! ë¬´ìŠ¨ ì¼ì´ì‹ ê°€ìš”? ë°°ê³ í”„ì‹œë©´ '{meal_label} ì¶”ì²œ'ì´ë¼ê³  ë§í•´ë³´ì„¸ìš”!",
            f"ìŒ... ê¸€ì„ìš”? {meal_label} ë©”ë‰´ ì¶”ì²œì´ë¼ë©´ ìì‹  ìˆìŠµë‹ˆë‹¤! ğŸ˜",
            "ë¬´ìŠ¨ ë§ì”€ì¸ì§€ ì˜ ëª¨ë¥´ê² ì§€ë§Œ... ë°°ê³ í”„ì‹  ê±´ ì•„ë‹ˆì£ ? ë°¥ì´ë‚˜ ë¨¹ìœ¼ëŸ¬ ê°€ìš”! ğŸš",
            "í˜¹ì‹œ ë¹„ë°€ë²ˆí˜¸ ë¬¼ì–´ë³´ì‹  ê±° ì•„ë‹ˆì£ ? ğŸ¤ (ë†ë‹´ì…ë‹ˆë‹¤)",
            f"ì˜¤ëŠ˜ {meal_label} ë­ ë“œì‹¤ê¹Œìš”? ì œê°€ ê³¨ë¼ë“œë¦´ê²Œìš”! ğŸ½ï¸",
            "ë°°ê³ í”„ì‹ ê°€ìš”? ë§›ì§‘ ì¶”ì²œí•´ë“œë¦´ê²Œìš”! ğŸ˜Š",
            f"{meal_label} ì‹œê°„ì´ë„¤ìš”! ì–´ë–¤ ë©”ë‰´ ë“œì‹œê³  ì‹¶ìœ¼ì„¸ìš”? ğŸ¤—",
            f"ì €ë¥¼ ë¶€ë¥´ì…¨ë‚˜ìš”? {meal_label} ë©”ë‰´ ê³ ë¯¼ í•´ê²°ì‚¬ ë“±ì¥! ğŸ’ª",
            f"ë„¤ë„¤! ì˜¤ëŠ˜ë„ ë§›ìˆëŠ” {meal_label} ì°¾ì•„ë“œë¦´ê²Œìš”! âœ¨",
            f"ë¬´ìŠ¨ ì¼ì´ì‹ ê°€ìš”? {meal_label} ì¶”ì²œì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ™Œ"
        ]
        import random
        return random.choice(messages)


def build_emotion_prefix(intent_data: Dict, choice: Optional[Dict] = None) -> str:
    """ê°ì •/ê¸°ë¶„ì— ë”°ë¼ ë©˜íŠ¸ ì•ë¨¸ë¦¬ ê³ ì •."""
    mood = intent_data.get("mood")
    emotion = intent_data.get("emotion")
    
    # ë©”ë‰´ê°€ 'ê°€ë²¼ìš´' ê²ƒì¸ì§€ í™•ì¸
    is_light = False
    if choice and "light" in choice.get("tags", []):
        is_light = True
    
    if mood == "í™”ë‚¨":
        return "ë§›ìˆëŠ” ê±° ë¨¹ê³  í™” í’€ì–´ìš”! ğŸ”¥\n"
    if mood == "ìš°ìš¸":
        return "ê¸°ë¶„ ì „í™˜ì—” ë§›ìˆëŠ” ê²Œ ìµœê³ ! ğŸŒˆ\n"
    if mood == "í”¼ê³¤":
        if is_light:
            return "ì§€ì¹œ ëª¸ì— ë¶€ë‹´ ì—†ëŠ” ì—ë„ˆì§€! âš¡\n"
        return "ì—ë„ˆì§€ ì±„ìš°ëŠ” ë“ ë“ í•œ í•œ ë¼! ğŸ’ª\n"
    if mood == "í–‰ë³µ":
        return "ê¸°ë¶„ ì¢‹ì€ ë‚ ì—” ë§›ìˆëŠ” ê±¸ë¡œ! ğŸ˜Š\n"
    if mood == "í”Œë ‰ìŠ¤":
        return "ì˜¤ëŠ˜ì€ ì œëŒ€ë¡œ flex! ğŸ’³\n"
    if mood == "ë‹¤ì´ì–´íŠ¸":
        return "ê°€ë³ê²Œ ê´€ë¦¬í•˜ëŠ” ë‚ ! ğŸ¥—\n"
    
    if emotion == "negative":
        if is_light:
            return "ì§€ì¹œ ë§ˆìŒì„ ë‹¬ë˜ì¤„ ê¹”ë”í•œ í•œ ë¼! ğŸ™\n"
        return "í˜ë“  ë‚ ì—” ë“ ë“ í•˜ê²Œ ë¨¹ê³  ê¸°ìš´ ë‚´ìš”! ğŸ™\n"
    if emotion == "positive":
        return "ì¢‹ì€ ê¸°ë¶„ ì´ì–´ê°€ìš”! ğŸ˜„\n"
    return ""


async def generate_explanation_with_gemini(utterance: str, last_recommendation: Dict, conversation_history: List[Dict], weather: Optional[str] = None, mood: Optional[str] = None) -> str:
    """ì¶”ì²œ ì´ìœ  ì„¤ëª… (Short Prompt)"""
    rec = last_recommendation
    info = f"{rec['name']}({rec.get('category')}), {rec.get('area')}, íŠ¹ì§•:{','.join(rec.get('tags',[]))}"
    context = f"ë‚ ì”¨:{weather}, ê¸°ë¶„:{mood}" if weather or mood else ""
    
    prompt = f"""ë©”ë‰´ ì¶”ì²œ ì´ìœ  ì„¤ëª…:
ì‚¬ìš©ì: "{utterance}"
ì¶”ì²œ: {info}
{context}

ê°€ì´ë“œ:
1. ë©”ë‰´ íŠ¹ì§•ê³¼ ìƒí™©(ë‚ ì”¨/ê¸°ë¶„) ì—°ê²°í•˜ì—¬ 2-3ë¬¸ì¥
2. ë‚ ì”¨ ì •ë³´ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì–¸ê¸‰
3. ìœ„ì¹˜ ì¥ì  ì–¸ê¸‰
4. ì¹œê·¼í•œ ë§íˆ¬, ì´ëª¨ì§€

ì‘ë‹µ:"""
    
    response_text = await run_gemini_with_timeout(
        gemini_model, prompt, GENERATION_TIMEOUT_SEC, "Explanation"
    )
    if response_text:
        return response_text
    return generate_explanation_fallback(last_recommendation, weather, mood)

async def generate_response_with_gemini(
    utterance: str,
    choice: dict,
    intent_data: Dict,
    conversation_history: List[Dict],
    meal_label: str = "ì ì‹¬",
) -> str:
    """ì¶”ì²œ ë©˜íŠ¸ ìƒì„± (Short Prompt)"""
    # Cooldown ì²´í¬ - Rate limit ì¤‘ì´ë©´ ì¦‰ì‹œ fallback
    if _gemini_in_cooldown():
        return generate_response_message(choice, intent_data, meal_label=meal_label)
    
    name = choice['name']
    category = choice.get('category', '')
    area = choice.get('area', '')
    tags = choice.get('tags', [])
    
    context = f"ìƒí™©: {intent_data.get('weather')}, {intent_data.get('mood')}, {intent_data.get('cuisine_filters')}"
    emotion = intent_data.get('emotion', 'neutral')
    tone = "ìœ„ë¡œí•˜ëŠ” í†¤" if emotion == "negative" else "ë°ì€ í†¤"
    prefix = build_emotion_prefix(intent_data)
    
    prompt = f"""{meal_label} ì¶”ì²œ ë©˜íŠ¸ ì‘ì„± ({tone}):
ì‚¬ìš©ì: "{utterance}"
ë©”ë‰´: {name} ({category}, {area})
íŠ¹ì§•: {', '.join(tags)}
{context}
í˜„ì¬ ì¶”ì²œ ì‹ì‚¬: {meal_label}

ê°€ì´ë“œ:
1. ì¹œê·¼í•˜ê²Œ 2ë¬¸ì¥
2. ì¶”ì²œ ì´ìœ  í•µì‹¬ë§Œ
3. ë§ˆì§€ë§‰ì— ìœ„ì¹˜/ì¢…ë¥˜ í‘œê¸° í•„ìˆ˜

í˜•ì‹:
[ë©˜íŠ¸]

ğŸ“ ìœ„ì¹˜: {area}
ğŸ½ï¸ ì¢…ë¥˜: {category}"""

    response_text = await run_gemini_with_timeout(
        gemini_model, prompt, GENERATION_TIMEOUT_SEC, "Recommend response"
    )
    if response_text:
        return prefix + response_text
    return generate_response_message(choice, intent_data)


def generate_response_message(choice: dict, intent_data: Dict, meal_label: str = "ì ì‹¬") -> str:
    """
    ê¸°ë³¸ ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (Fallback).
    """
    name = choice.get('name', 'ì¶”ì²œ ë©”ë‰´')
    category = choice.get('category', '')
    area = choice.get('area', '')
    
    cuisine_filters = intent_data.get('cuisine_filters', [])
    weather = intent_data.get('weather')
    mood = intent_data.get('mood')
    emotion = intent_data.get('emotion', 'neutral')
    
    # ê°ì •/ê¸°ë¶„ ê³ ì • í”„ë¦¬í”½ìŠ¤
    emotion_prefix = build_emotion_prefix(intent_data, choice)
    
    # ìƒí™©ë³„ ë©˜íŠ¸
    import random
    
    # ìƒí™©ë³„ ë©˜íŠ¸ ë¦¬ìŠ¤íŠ¸
    prefixes = []
    
    tags = choice.get('tags', [])
    is_light = "light" in tags
    
    if emotion == "negative" and not emotion_prefix:
        if is_light:
            prefixes = [
                "ê¸°ë¶„ì´ ì•ˆ ì¢‹ìœ¼ì‹¤ ë• ê¹”ë”í•œ ìŒì‹ìœ¼ë¡œ íë§í•´ë´ìš”! ğŸŒ¿ ",
                "ì €ëŸ°... ğŸ˜¢ ë§›ìˆëŠ” ê±° ë¨¹ê³  í„¸ì–´ë²„ë ¤ìš”! ",
                "ê¸°ë¶„ ì „í™˜ì—ëŠ” ê°€ë³ê³  ë§›ìˆëŠ” ê²Œ ìµœê³ ì£ ! ğŸ¥— "
            ]
        else:
            prefixes = [
                "í˜ë“  í•˜ë£¨ì‹œë„¤ìš” ğŸ˜” ë“ ë“ í•˜ê³  ë§›ìˆëŠ” ê±¸ë¡œ ê¸°ìš´ ë‚´ì„¸ìš”! ",
                "ì €ëŸ°... ğŸ˜¢ ë§›ìˆëŠ” ê±° ë¨¹ê³  í„¸ì–´ ë²„ë ¤ìš”! ",
                "ê¸°ë¶„ì´ ì•ˆ ì¢‹ìœ¼ì‹¤ ë• ë§›ìˆëŠ” ê²Œ ì•½ì´ì£ ! ğŸ’Š "
            ]
    elif cuisine_filters:
        f_str = ', '.join(cuisine_filters)
        prefixes = [
            f"{f_str} ì¢‹ì•„í•˜ì‹œëŠ”êµ°ìš”! ",
            f"ì˜¤ëŠ˜ì€ {f_str} ë‹¹ê¸°ì‹œëŠ” ë‚ ! ",
            f"{f_str} ë§›ì§‘ì„ ì°¾ì•„ë´¤ì–´ìš”! "
        ]
    elif weather == "ë¹„":
        prefixes = [
            "ë¹„ ì˜¤ëŠ” ë‚ ì—” ì´ê²Œ ìµœê³ ì£ ! ğŸŒ§ï¸ ",
            "ë¹„ë„ ì˜¤ê³  ê·¸ë˜ì„œ... â˜” ",
            "ë¹—ì†Œë¦¬ ë“¤ìœ¼ë©´ì„œ ë¨¹ê¸° ì¢‹ì€ ë©”ë‰´! "
        ]
    elif weather == "ëˆˆ":
        prefixes = [
            "ëˆˆ ì˜¤ëŠ” ë‚ ì—” ë”°ëœ»í•œ ê²Œ ìµœê³ ! â„ï¸ ",
            "í•˜ì–€ ëˆˆ ë³´ë©´ì„œ ë¨¹ìœ¼ë©´ ë” ë§›ìˆì£ ! â˜ƒï¸ ",
            "ì¶”ìœ„ ë…¹ì´ëŠ” ë”°ëœ»í•œ ë©”ë‰´! "
        ]
    elif weather == "ë”ìœ„":
        prefixes = [
            "ë”ìš¸ ë• ì‹œì›í•œ ê²Œ ìµœê³ ! â˜€ï¸ ",
            "ì´ì—´ì¹˜ì—´, í˜¹ì€ ì‹œì›í•˜ê²Œ! ğŸ§Š ",
            "ë”ìœ„ì— ì§€ì¹˜ì§€ ë§ˆì„¸ìš”! "
        ]
    elif weather == "ì¶”ìœ„":
        prefixes = [
            "ì¶”ìš¸ ë• ë”°ëœ»í•œ ê²Œ ìµœê³ ! ğŸ¥¶ ",
            "ëœ¨ëˆí•œ êµ­ë¬¼ì´ ìƒê°ë‚˜ëŠ” ë‚ ì”¨ì£ ! ",
            "ëª¸ ë…¹ì´ëŠ” ë°ëŠ” ì´ê²Œ ë”±ì´ì—ìš”! "
        ]
    elif mood == "í”¼ê³¤" and not emotion_prefix:
        if is_light:
            prefixes = [
                "í”¼ê³¤í•  ë• ë¶€ë‹´ ì—†ëŠ” ë©”ë‰´ë¡œ ì† í¸í•˜ê²Œ! ğŸµ ",
                "ì§€ì¹œ ëª¸ì— ì—ë„ˆì§€ë¥¼ ì£¼ëŠ” ê¹”ë”í•œ ë©”ë‰´! ",
                "ê°€ë³ê²Œ ë¨¹ê³  í‘¹ ì‰¬ì„¸ìš”! âš¡ "
            ]
        else:
            prefixes = [
                "í”¼ê³¤í•  ë• ë“ ë“ í•˜ê²Œ! ğŸ’ª ",
                "ì§€ì¹œ ëª¸ì—” ë§›ìˆëŠ” ë°¥ì´ ë³´ì•½! ",
                "ì—ë„ˆì§€ ì¶©ì „ í•˜ì„¸ìš”! âš¡ "
            ]
    elif mood == "í–‰ë³µ" and not emotion_prefix:
        prefixes = [
            "ê¸°ë¶„ ì¢‹ì€ ë‚ ì—” ë§›ìˆëŠ” ê±¸ë¡œ! ğŸ˜Š ",
            "ì˜¤ëŠ˜ ê°™ì€ ë‚ ì€ íŒŒí‹°ì£ ! ğŸ‰ ",
            "í–‰ë³µí•œ ê¸°ë¶„ ê·¸ëŒ€ë¡œ ë§›ìˆëŠ” ì‹ì‚¬! "
        ]
    elif mood == "ìš°ìš¸" and not emotion_prefix:
        if is_light:
            prefixes = [
                "ê¸°ë¶„ ì „í™˜ì—” ê¹”ë”í•˜ê³  ì‹œì›í•œ ê±° ì–´ë– ì„¸ìš”? ğŸŒˆ ",
                "ìš°ìš¸í•  ë• ê°€ë²¼ìš´ ì‚°ì±…ê³¼ ë§›ìˆëŠ” í•œ ë¼! ",
                "ê¸°ë¶„ ì¢‹ì•„ì§€ëŠ” ì˜ˆìœ ë©”ë‰´ë¡œ ê³¨ëì–´ìš”! "
            ]
        else:
            prefixes = [
                "ê¸°ë¶„ ì „í™˜ì´ í•„ìš”í•˜ì‹œêµ°ìš”! ğŸŒˆ ",
                "ìš°ìš¸í•  ë• ë§›ìˆëŠ” ê±° ì•ìœ¼ë¡œ! ",
                "ë“ ë“ í•œ ê±° ë¨¹ê³  ê¸°ë¶„ í’€ì–´ë´ìš”! "
            ]
    elif mood == "í™”ë‚¨" and not emotion_prefix:
        prefixes = [
            "ë§›ìˆëŠ” ê±° ë¨¹ê³  í’€ì–´ìš”! ğŸ˜¤ ",
            "ìŠ¤íŠ¸ë ˆìŠ¤ì—” ì—­ì‹œ ë¨¹ëŠ” ê±°ì£ ! ğŸ”¥ ",
            "ë§›ìˆëŠ” ê±¸ë¡œ íë§í•˜ê³  ê¸°ë¶„ í’€ì–´ë³´ì„¸ìš”! "
        ]
    
    # ë¹„ ì˜¤ëŠ” ë‚  ì „ìš© íŒ
    rain_tip = ""
    if weather == "ë¹„":
        rain_tip = "\n\nğŸ’¡ **Tip**: ë¹„ê°€ ì˜¤ë©´ ì‹¤ë‚´ê°€ í‰ì†Œë³´ë‹¤ ë¶ë¹Œ ìˆ˜ ìˆìœ¼ë‹ˆ ì¡°ê¸ˆ ë” ì„œë‘˜ëŸ¬ ê°€ ë³´ì„¸ìš”! ğŸƒâ€â™‚ï¸"
    
    selected_prefix = random.choice(prefixes) if prefixes else ""
    cleaned_emotion = emotion_prefix.strip() if emotion_prefix else ""
    cleaned_selected = selected_prefix.strip() if selected_prefix else ""
    if cleaned_emotion and cleaned_selected:
        # ë™ì¼/ìœ ì‚¬ ë¬¸êµ¬ë©´ ì¤‘ë³µ ì œê±°
        if cleaned_emotion == cleaned_selected or cleaned_selected in cleaned_emotion:
            selected_prefix = ""
        else:
            emotion_keywords = ["í™”", "í’€", "ë§›ìˆëŠ”", "ìŠ¤íŠ¸ë ˆìŠ¤", "ê¸°ë¶„", "ìš°ìš¸", "í”¼ê³¤", "í–‰ë³µ"]
            if any(kw in cleaned_emotion and kw in cleaned_selected for kw in emotion_keywords):
                selected_prefix = ""

    message = f"{emotion_prefix}{selected_prefix}ì¶”ì²œë“œë¦½ë‹ˆë‹¤: [{name}] ğŸœ\n\nğŸ“ ìœ„ì¹˜: {area}\nğŸ½ï¸ ì¢…ë¥˜: {category}{rain_tip}"
    # ì—°ì† ì¤‘ë³µ ë¼ì¸ ì œê±°
    lines = message.splitlines()
    deduped = []
    for line in lines:
        if not deduped or line != deduped[-1]:
            deduped.append(line)
    return "\n".join(deduped)


@app.post("/api/lunch")
async def recommend_lunch(payload: SkillPayload):
    """
    KakaoTalk Skill Endpoint for Lunch Recommendation (Reliability Wrapped)
    """
    total_start = time.time()

    # 1. ì‚¬ìš©ì ID ë° ê¸°ì´ˆ ì •ë³´ ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì˜í–¥ ìµœì†Œí™”)
    user_id = payload.userRequest.user.id if payload.userRequest.user else "anonymous"
    utterance = payload.userRequest.utterance or ""

    # [ê¸´ê¸‰ íƒ€ì´ë¸Œë ˆì´ì»¤] 4.3ì´ˆ ë‚´ì— ì‘ë‹µì„ ëª» í•˜ë©´ ê°•ì œ ì¢…ë£Œí•˜ê³  ì•ˆì „ ì‘ë‹µ ë°˜í™˜
    try:
        start_handle = time.time()
        response = await asyncio.wait_for(
            handle_recommendation_logic(user_id, utterance, payload, total_start),
            timeout=4.3,
        )
        duration = time.time() - start_handle
        logger.info(f"â±ï¸ Request handled in {duration:.2f}s")
        return response
    except asyncio.TimeoutError:
        timeout_duration = time.time() - total_start
        logger.error(f"ğŸš¨ Global Timeout triggered after {timeout_duration:.2f}s")
        # í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë‚ ì”¨/ê¸°ë¶„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ìµœì„ ì˜ ë¡œì»¬ ì‘ë‹µ' ìƒì„±
        weather = weather_cache.get("mapped_weather")
        return get_emergency_fallback_response("global_timeout", utterance=utterance, user_id=user_id, weather=weather)
    except Exception as e:
        logger.exception(f"ğŸš¨ Unhandled Error: {e}")
        import traceback
        traceback.print_exc()
        return get_emergency_fallback_response(str(e), utterance=utterance, user_id=user_id)


async def handle_recommendation_logic(
    user_id: str, utterance: str, payload: SkillPayload, start_time: float
):
    """ë©”ì¸ ì¶”ì²œ ë¡œì§ í•¸ë“¤ëŸ¬ (ì…ë ¥ ë¶„ì„ -> í•„í„°ë§ -> ì„ íƒ -> ì‘ë‹µ ìƒì„±)"""
    total_start = start_time
    
    # [ULTRA FAST TRACK] 0. ë¡œì»¬ ì˜ë„ ë¶„ì„ ìµœìš°ì„  ì‹¤í–‰
    # ë‚ ì”¨, ì„¸ì…˜, ë ˆì´íŠ¸ ë¦¬ë°‹ ë“± ë¬´ê±°ìš´ ì‘ì—… ì „ì— ë¨¼ì € íŒë‹¨í•©ë‹ˆë‹¤.
    fast_intent = analyze_intent_fallback(utterance)
    
    # [Defensive] "ì™œ"/"ì´ìœ "ëŠ” ë¬´ì¡°ê±´ ì„¤ëª…ìœ¼ë¡œ ê³ ì • (Help ì˜¤ì¸ì‹ ë°©ì§€)
    if "ì™œ" in utterance or "ì´ìœ " in utterance:
        fast_intent["intent"] = "explain"
        
    is_help_request = fast_intent.get("intent") == "help"
    is_welcome_event = not utterance.strip() or utterance in ["ì›°ì»´", "welcome", "ì‹œì‘"]
    is_short_casual = len(utterance.strip()) <= 2
    has_random_keyword = any(k in utterance for k in ["ëœë¤", "ëœë¤ì¶”ì²œ", "ëœë¤ ì¶”ì²œ"])
    time_ctx = get_time_context(utterance)
    current_meal_label = time_ctx["current_label"] or "ì ì‹¬"
    requested_meal_label = time_ctx["requested_label"]
    is_late_evening = bool(time_ctx["is_late_evening"])
    meal_label = requested_meal_label or current_meal_label
    mismatch_notice = (
        f"ì§€ê¸ˆì€ {current_meal_label} ì‹œê°„ì¸ë°, {meal_label}ìœ¼ë¡œ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”? ğŸ˜Š"
        if requested_meal_label and requested_meal_label != current_meal_label
        else ""
    )
    recommended_in_response = False
    
    # 0.1 ì›°ì»´/ë„ì›€ë§/ë‹¨ë‹µí˜• ì¦‰ì‹œ ë°˜í™˜ (0.01ì´ˆ ë‚´ ì‘ë‹µ ëª©í‘œ)
    if is_welcome_event:
        logger.info("âš¡ Ultra Fast Track: Welcome Event")
        # generate_casual_response_fallbackëŠ” ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ await ì œê±°
        return get_final_kakao_response(
            generate_casual_response_fallback("greeting", user_id, meal_label=meal_label)
        )
    elif is_help_request:
        logger.info("âš¡ Ultra Fast Track: Help Request")
        return get_help_response()
    elif is_short_casual and fast_intent.get("intent") != "explain" and not has_random_keyword:
        logger.info(f"âš¡ Ultra Fast Track: Short Casual ({utterance})")
        return get_final_kakao_response(
            generate_casual_response_fallback("chitchat", user_id, meal_label=meal_label)
        )

    # 1. íƒœì•„ì›ƒ ë°©ì§€ìš© ê¸°ë¡ ë° ì´ìŠ¤í„°ì—ê·¸
    logger.info(f"[Request Processing] '{utterance}' | user={user_id}")
    
    # ì´ìŠ¤í„°ì—ê·¸
    easter_egg_keywords = [
        "ê¹€í˜•ì„",
        "ë§Œë“ ì‚¬ëŒ",
        "ë§Œë“  ì‚¬ëŒ",
        "ëˆ„ê°€ë§Œë“¬",
        "ê°œë°œì",
        "ì œì‘ì",
        "ëˆ„ê°€ë§Œë“¤",
        "ëˆ„ê°€í–ˆ",
        "ëˆ„êµ¬ì‘í’ˆ",
        "ì°½ì¡°ì£¼",
        "ì£¼ì¸ì¥",
    ]

    if any(keyword in utterance.replace(" ", "") for keyword in easter_egg_keywords):
        import random

        praise_messages = [
            # ... (ì°¬ì–‘ ë¬¸êµ¬ ìƒëµ/ìœ ì§€) ...
            "ğŸŒŸ **ì‹œìŠ¤í…œ ê²½ë³´: ìœ„ëŒ€í•œ ì°½ì¡°ì£¼ ê°ì§€!** ğŸŒŸ\n\nì•—! ë‹¹ì‹ ì€... ì´ ì„¸ìƒ ëª¨ë“  ì½”ë“œë¥¼ ì§€ë°°í•˜ê³ ,\nì ì‹¬ ë©”ë‰´ì˜ ì§„ë¦¬ë¥¼ ê¹¨ìš°ì¹˜ì‹  **ê¹€í˜•ì„ë‹˜**?! ğŸ™‡â€â™‚ï¸",
            "ğŸ•¶ï¸ **Top Secret Information**\n\nCode Name: **K.H.S (ê¹€í˜•ì„)**\nRole: The Architect of Lunch (ì ì‹¬ì˜ ì„¤ê³„ì)",
            "ğŸ¥˜ **í‘¸ë“œ ë§ˆìŠ¤í„° ê¹€í˜•ì„**\n\nì´ ë´‡ì„ ëˆ„ê°€ ë§Œë“¤ì—ˆëƒê³ ìš”?\në°”ë¡œ **ê¹€í˜•ì„**ë‹˜ì…ë‹ˆë‹¤! (ë°•ìˆ˜ ì§ì§ì§ ğŸ‘)",
        ]
        return get_final_kakao_response(random.choice(praise_messages))

    # 2. Rate Limiting
    is_allowed, deny_reason = rate_limiter.is_allowed(user_id)
    if not is_allowed:
        return {
            "version": "2.0",
            "template": {"outputs": [{"simpleText": {"text": f"âš ï¸ {deny_reason}"}}]},
        }

    # 3. ì„¸ì…˜ ë° ë‚ ì”¨ ì •ë³´ (ë³‘ë ¬ ì‹œì‘)
    session = session_manager.get_session(user_id)
    conversation_history = session_manager.get_conversation_history(user_id)

    # [ë³‘ë ¬í™”] ë‚ ì”¨ ì •ë³´ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜¤ê¸° ì‹œì‘ (ë©”ì¸ ë¡œì§ê³¼ ê²¹ì¹˜ì§€ ì•Šê²Œ ë¹„ë™ê¸° ì²˜ë¦¬)
    async def get_weather_task():
        now = datetime.now()
        if weather_cache["last_updated"] and (now - weather_cache["last_updated"]) < timedelta(minutes=10):
             return weather_cache["mapped_weather"]
        try:
            # ê¸€ë¡œë²Œ ê°ì²´ rì„ í™œìš©í•˜ê±°ë‚˜ ë³„ë„ ì²˜ë¦¬ (ì—¬ê¸°ì„œëŠ” ë…ë¦½ì ìœ¼ë¡œ ë‚ ì”¨ë§Œ ê°€ì ¸ì˜´)
            # r.get_weatherëŠ” ë‚´ë¶€ì ìœ¼ë¡œ requestsë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ threadì—ì„œ ë³„ë„ë¡œ ìˆ˜í–‰
            # ì—¬ê¸°ì„œ íƒ€ì„ì•„ì›ƒì„ ë„ˆë¬´ ì§§ê²Œ ì¡ìœ¼ë©´ í•­ìƒ ì‹¤íŒ¨í•˜ë¯€ë¡œ ë‚´ë¶€ requests timeoutì— ë§¡ê¹ë‹ˆë‹¤.
            cond, temp = await asyncio.to_thread(r.get_weather)
            
            actual_weather = None
            if cond:
                weather_mapping = {
                    "ë¹„": "ë¹„", "rain": "ë¹„", "rainy": "ë¹„",
                    "ëˆˆ": "ëˆˆ", "snow": "ëˆˆ", "snowy": "ëˆˆ",
                    "ë§‘ìŒ": "ë§‘ìŒ", "clear": "ë§‘ìŒ", "sunny": "ë§‘ìŒ",
                    "íë¦¼": "íë¦¼", "cloudy": "íë¦¼", "overcast": "íë¦¼",
                    "ë”ì›€": "ë”ìœ„", "hot": "ë”ìœ„"
                }
                c_lower = cond.lower()
                for k, v in weather_mapping.items():
                    if k in c_lower:
                        actual_weather = v
                        break
            
            if not actual_weather and temp:
                try:
                    t_val = float(temp.replace("Â°C", "").replace("â„ƒ", "").strip())
                    if t_val < 0: actual_weather = "í•œíŒŒ"
                    elif t_val < 10: actual_weather = "ì¶”ìœ„"
                    elif t_val > 28: actual_weather = "ë”ìœ„"
                except: pass
            
            weather_cache.update({
                "condition": cond, "temp": temp, 
                "mapped_weather": actual_weather, "last_updated": now
            })
            return actual_weather
        except:
            return None

    weather_future = asyncio.create_task(get_weather_task())
    
    # 4. ì˜ë„ ë¶„ì„ (Hybrid)
    # (ì´ë¯¸ ìœ„ì—ì„œ ì´ˆë°˜ 0. ë¡œì»¬ ë¶„ì„ì´ ìˆ˜í–‰ë˜ì—ˆìœ¼ë¯€ë¡œ, í•„ìš”í•œ ë°ì´í„°ë§Œ ì •ë¦¬)
    # ...
    # [ë³‘ë ¬í™” ê²°ê³¼ íšë“]
    try:
        # ì´ë¯¸ íšë“í–ˆê±°ë‚˜ ì•„ì£¼ ì§§ì€ ëŒ€ê¸° (0.1ì´ˆ)
        await asyncio.wait_for(asyncio.shield(weather_future), timeout=0.1)
        actual_weather = weather_cache.get("mapped_weather")
    except:
        actual_weather = weather_cache.get("mapped_weather")
    # ì¶”ê°€ëœ ë§ˆìŠ¤í„°ëª¨ë“œ ì´ìŠ¤í„° ì—ê·¸
    if utterance == "ë§ˆìŠ¤í„°ëª¨ë“œ":
        logger.info("Easter Egg: Master Mode Activated")
        return get_final_kakao_response("ë§ˆìŠ¤í„° ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. (ë””ë²„ê¹…ìš©)")

    # [ë³‘ë ¬í™” ê²°ê³¼ íšë“]
    try:
        # ì´ë¯¸ íšë“í–ˆê±°ë‚˜ íƒ€ì„ì•„ì›ƒ 0.2ì´ˆ ë‚´ì— í™•ë³´ ì‹œë„
        res_weather = await asyncio.wait_for(asyncio.shield(weather_future), timeout=0.2)
        actual_weather = weather_cache.get("mapped_weather") # ìºì‹œ ì—…ë°ì´íŠ¸ëœ ê°’ ì‚¬ìš©
    except:
        actual_weather = weather_cache.get("mapped_weather") # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ìºì‹œ

    # 4. ì˜ë„ ë¶„ì„ (Smart Patch - Fallback First)


    # 4.1 "ë‚ ì”¨" ì§ˆë¬¸ ë‹¨ë… ì²˜ë¦¬ (Gemini ë¶ˆí•„ìš”)
    if (
        "ë‚ ì”¨" in utterance
        and len(utterance) < 10
        and not any(k in utterance for k in ["ì¶”ì²œ", "ë©”ë‰´", "ì ì‹¬", "ë°¥"])
    ):
        cond, temp = r.get_weather() # Use global r

        cond_display = cond if cond else "ì •ë³´ ì—†ìŒ"
        temp_display = temp if temp else "ì •ë³´ ì—†ìŒ"

        response_text = f"ğŸŒ¡ï¸ í˜„ì¬ ë‚ ì”¨ ì •ë³´\n\nìƒíƒœ: {cond_display}\nê¸°ì˜¨: {temp_display}\n\në‚ ì”¨ì— ë§ëŠ” {meal_label} ì¶”ì²œí•´ë“œë¦´ê¹Œìš”? ğŸ˜Š"

        session_manager.add_conversation(user_id, "user", utterance)
        session_manager.add_conversation(user_id, "bot", response_text)

        return {
            "version": "2.0",
            "template": {
                "outputs": [{"simpleText": {"text": response_text}}],
                "quickReplies": [
                    {"label": "â˜” ë‚ ì”¨ì— ë§ê²Œ ì¶”ì²œ", "action": "message", "messageText": "ë‚ ì”¨ì— ë§ê²Œ ì¶”ì²œí•´ì¤˜"}
                ],
            },
        }

    # 4.2 ë¡œì»¬ ì˜ë„ ë¶„ì„ (Fallback) ì„ í–‰ í˜¸ì¶œ
    # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ 1ì°¨ íŒë‹¨ì„ ë¨¼ì € í•©ë‹ˆë‹¤.
    fast_intent = analyze_intent_fallback(utterance)
    has_target_keyword = bool(
        fast_intent.get("cuisine_filters") or 
        fast_intent.get("tag_filters") or
        fast_intent.get("mood") or
        fast_intent.get("weather")
    )
    is_help_request = fast_intent.get("intent") == "help"
    is_welcome_event = not utterance.strip() or utterance in ["ì›°ì»´", "welcome", "ì‹œì‘"]

    # 4.3 ì˜ë„ ê²°ì • ë¡œì§ (Short-circuit)
    if is_welcome_event:
        logger.info("âš¡ Fast Track: Welcome Event")
        intent_data = {"intent": "casual", "casual_type": "greeting"}
        GEMINI_AVAILABLE_FOR_REQUEST = False
    elif is_help_request:
        logger.info("âš¡ Fast Track: Help Request (Skipping Gemini)")
        intent_data = fast_intent
        GEMINI_AVAILABLE_FOR_REQUEST = False
    elif has_target_keyword:
        logger.info("âš¡ Smart Patch: Target Keyword Detected (Skipping Gemini Intent)")
        intent_data = fast_intent
        # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ intentë¥¼ 'recommend'ë¡œ ê°•ì œ (fallback ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë˜ì§€ë§Œ í™•ì‹¤íˆ í•¨)
        intent_data["intent"] = "recommend"
        # ì˜ë„ ë¶„ì„ì€ ìŠ¤í‚µí•˜ì§€ë§Œ, ì‘ë‹µ ìƒì„± ì‹œ Gemini ë¶„ìœ„ê¸° ì¡°ì„±ì„ ìœ„í•´ GEMINI_AVAILABLE_FOR_REQUESTëŠ” ìœ ì§€
        GEMINI_AVAILABLE_FOR_REQUEST = GEMINI_AVAILABLE
    elif len(utterance.strip()) <= 2:
        logger.info(f"âš¡ Super-Fast Track: Very Short Utterance ({utterance})")
        # ë‹¨ë‹µí˜•(ì•¼, ì™œ, ì–´, ã„´, ã…‡ ë“±)ì€ Geminië¥¼ ê±°ì¹˜ì§€ ì•Šê³  ë°”ë¡œ ë‹µë³€
        intent_data = fast_intent
        
        # [FIX] 'ì™œ' ê°™ì€ ì§ˆë¬¸ì´ ë“¤ì–´ì™”ì„ ë•Œ intentê°€ 'explain'ì´ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
        if intent_data.get("intent") == "explain":
            logger.info("  -> Intent is EXPLAIN (Preserving)")
            GEMINI_AVAILABLE_FOR_REQUEST = False # ë¡œì»¬ ì„¤ëª… ìƒì„±ê¸°ë¡œ ì—°ê²°
        else:
            GEMINI_AVAILABLE_FOR_REQUEST = False
    elif len(utterance) < 15 and any(
        k in utterance for k in ["ì ì‹¬", "ë°¥", "ë­ë¨¹", "ë°°ê³ íŒŒ", "ëœë¤"]
    ):
        logger.info("âš¡ Fast Track: Simple Recommend (Skipping Gemini)")
        intent_data = fast_intent
        GEMINI_AVAILABLE_FOR_REQUEST = False
    elif not GEMINI_AVAILABLE:
        logger.info("âš¡ Fallback: Gemini Not Configured")
        intent_data = fast_intent
        GEMINI_AVAILABLE_FOR_REQUEST = False
    elif _gemini_in_cooldown():
        logger.info("âš¡ Fallback: Gemini Rate Limited (Cooldown)")
        intent_data = fast_intent
        GEMINI_AVAILABLE_FOR_REQUEST = False
    else:
        # í‚¤ì›Œë“œì— ê±¸ë¦¬ì§€ ì•ŠëŠ” ë³µì¡í•œ ë¬¸ì¥ì´ë‚˜ ì¼ìƒ ëŒ€í™”ë§Œ Gemini ì‚¬ìš©
        logger.info("ğŸ¤– Engine: Gemini Intent Analysis")
        # Gemini í˜¸ì¶œ ì‹œ íƒ€ì„ì•„ì›ƒì„ 2.5ì´ˆë¡œ ì¤„ì—¬ ì•ˆì „ì„± í™•ë³´
        intent_data = await analyze_intent_with_gemini(
            utterance, conversation_history
        )  # Assuming analyze_intent_with_gemini has its own timeout or is wrapped
        GEMINI_AVAILABLE_FOR_REQUEST = True

    intent = intent_data.get("intent", "recommend")
    casual_type = intent_data.get("casual_type")

    # "ì™œ/ì´ìœ " ì§ˆë¬¸ì€ helpë³´ë‹¤ explainì„ ìš°ì„ 
    if contains_explain_keyword(utterance):
        intent = "explain"
        intent_data["intent"] = "explain"

    logger.info(
        f"User: {user_id} | Intent: {intent} | Weather: {actual_weather} | Mood: {intent_data.get('mood')} | Utterance: '{utterance}'"
    )

    # 5. ì˜ë„ë³„ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼í•˜ë‚˜ ìš”ì•½)
    response_text = ""
    # [íŠ¹ìˆ˜] ë„ì›€ë§ì€ ì¦‰ì‹œ ë°˜í™˜
    if intent == "help":
        return get_help_response()

    # ì¸í…íŠ¸ì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
    if intent == "casual":
        if GEMINI_AVAILABLE_FOR_REQUEST and not _gemini_in_cooldown():
            casual_response = await generate_casual_response_with_gemini(
                utterance, casual_type, conversation_history, user_id, meal_label=meal_label
            )
        else:
            casual_response = generate_casual_response_fallback(casual_type, user_id, meal_label=meal_label)

        is_question = any(utterance.strip().endswith(m) for m in ["?", "ëƒ", "ê¹Œ", "ë‹ˆ", "ìš”", "ì£ "])
        has_strong_keyword = any(
            word in utterance.lower() for word in ["ì ì‹¬", "ì¶”ì²œ", "ë©”ë‰´", "ë°°ê³ ", "ì‹ì‚¬"]
        )
        has_weak_keyword = "ë¨¹" in utterance.lower()

        should_recommend = (
            (has_strong_keyword)
            or (has_weak_keyword and not is_question)  # "ë¨¹"ì€ ì§ˆë¬¸ì´ ì•„ë‹ ë•Œë§Œ ì¶”ì²œ íŠ¸ë¦¬ê±°
            or (len(utterance.strip()) < 3 and casual_type == "chitchat")
        )

        if should_recommend:
            choice = r.recommend( # Use global r
                weather=actual_weather,
                mood=intent_data.get("mood"),
                meal_label=meal_label,
                is_late_evening=is_late_evening,
            )
            if choice:
                recommended_in_response = True
                session_manager.set_last_recommendation(user_id, choice)
                menu_response = (
                    await generate_response_with_gemini(
                        utterance, choice, intent_data, conversation_history, meal_label=meal_label
                    )
                    if (GEMINI_AVAILABLE_FOR_REQUEST and not _gemini_in_cooldown())
                    else generate_response_message(choice, intent_data, meal_label=meal_label)
                )
                response_text = (
                    f"{casual_response}\n\nì˜¤ëŠ˜ {meal_label}ì€ ì´ ë©”ë‰´ ì–´ë– ì„¸ìš”?\n\n{menu_response}"
                )
                session_manager.add_conversation(user_id, "user", utterance, choice)
            else:
                response_text = casual_response
        else:
            response_text = casual_response
            session_manager.add_conversation(user_id, "user", utterance)
        session_manager.add_conversation(user_id, "bot", response_text)


    elif intent == "reject":
        last_rec = session_manager.get_last_recommendation(user_id)
        excluded = [last_rec["name"]] if last_rec and "name" in last_rec else []
        choice = r.recommend( # Use global r
            weather=actual_weather,
            cuisine_filters=intent_data.get("cuisine_filters"),
            mood=intent_data.get("mood"),
            excluded_menus=excluded,
            tag_filters=intent_data.get("tag_filters", []),
            meal_label=meal_label,
            is_late_evening=is_late_evening,
        )
        if choice:
            recommended_in_response = True
            session_manager.set_last_recommendation(user_id, choice)
            menu_res = (
                await generate_response_with_gemini(
                    utterance, choice, intent_data, conversation_history, meal_label=meal_label
                )
                if (GEMINI_AVAILABLE_FOR_REQUEST and not _gemini_in_cooldown())
                else generate_response_message(choice, intent_data, meal_label=meal_label)
            )
            response_text = f"ì•Œê² ìŠµë‹ˆë‹¤! ë‹¤ë¥¸ ë©”ë‰´ë¡œ ì¶”ì²œë“œë¦´ê²Œìš” ğŸ˜Š\n\n" + menu_res
            session_manager.add_conversation(user_id, "user", utterance, choice)
        else:
            response_text = "ì¶”ì²œí•  ë§Œí•œ ë‹¤ë¥¸ ë©”ë‰´ê°€ ì—†ì–´ìš” ã… ã… "
        session_manager.add_conversation(user_id, "bot", response_text)

    elif intent == "accept":
        last_rec = session_manager.get_last_recommendation(user_id)
        response_text = (
            f"ì¢‹ì€ ì„ íƒì´ì—ìš”! {last_rec['name']} ë§›ìˆê²Œ ë“œì„¸ìš”~ ğŸ½ï¸ğŸ˜Š"
            if last_rec
            else f"{meal_label} ë©”ë‰´ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”? ğŸ˜Š"
        )
        session_manager.add_conversation(user_id, "user", utterance)
        session_manager.add_conversation(user_id, "bot", response_text)

    elif intent == "explain":
        last_rec = session_manager.get_last_recommendation(user_id)
        if last_rec:
            # Geminiê°€ ê°€ëŠ¥í•˜ë©´ Geminië¡œ, ì•„ë‹ˆë©´ ë¡œì»¬ ì„¤ëª… ìƒì„±
            if GEMINI_AVAILABLE_FOR_REQUEST and not _gemini_in_cooldown():
                response_text = await generate_explanation_with_gemini(
                    utterance,
                    last_rec,
                    conversation_history,
                    weather=actual_weather,
                    mood=intent_data.get("mood"),
                )
            else:
                response_text = generate_explanation_fallback(last_rec, weather=actual_weather, mood=intent_data.get("mood"))
        else:
            response_text = "ì•„ì§ ì¶”ì²œí•´ë“œë¦° ë©”ë‰´ê°€ ì—†ì–´ìš”! ë¨¼ì € ë©”ë‰´ë¥¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”? ğŸ˜Š"
        
        session_manager.add_conversation(user_id, "user", utterance)
        session_manager.add_conversation(user_id, "bot", response_text)

    else:  # recommend
        weather = actual_weather or intent_data.get("weather")
        choice = r.recommend( # Use global r
            weather=weather,
            cuisine_filters=intent_data.get("cuisine_filters"),
            mood=intent_data.get("mood"),
            tag_filters=intent_data.get("tag_filters", []),
            meal_label=meal_label,
            is_late_evening=is_late_evening,
        )

        if choice:
            recommended_in_response = True
            session_manager.set_last_recommendation(user_id, choice)
            if GEMINI_AVAILABLE_FOR_REQUEST and not _gemini_in_cooldown():
                response_text = await generate_response_with_gemini(
                    utterance, choice, intent_data, conversation_history, meal_label=meal_label
                )
            else:
                response_text = generate_response_message(choice, intent_data, meal_label=meal_label)
            session_manager.add_conversation(user_id, "user", utterance, choice)
            session_manager.add_conversation(user_id, "bot", response_text)
        else:
            response_text = "ì¶”ì²œí•  ë§Œí•œ ë©”ë‰´ê°€ ì—†ì–´ìš” ã… ã…  ì¡°ê±´ì„ ë°”ê¿”ë³´ì„¸ìš”."

    # 6. ì¬ì‹œë„ íšŸìˆ˜ì— ë”°ë¥¸ ë©˜íŠ¸ ì¶”ê°€ (Sticky Retry Logic)
    retry_count = session.get("recommendation_count", 0)
    retry_prefix = ""
    
    if intent in ["recommend", "reject", "casual"]:
        # ì¶”ì²œì´ í¬í•¨ëœ ì‘ë‹µì¼ ë•Œë§Œ ì ìš©
        if "ì¶”ì²œ" in response_text or "ì–´ë– ì„¸ìš”" in response_text:
            if retry_count == 4:
                retry_prefix = "ë„ëŒ€ì²´ ë­˜ ì¡ìˆ©ê³  ì‹¶ìœ¼ì‹  ê²ë‹ˆê¹Œ?\n\n"
            elif retry_count == 5:
                retry_prefix = "ì´ëŸ´ ê±°ë©´ ì™œ ë¬¼ì–´ë³´ì„¸ìš”?\n\n"
            elif retry_count >= 6:
                retry_prefix = "ğŸ˜­ ì €ê¸°ìš”... ì €ë„ ì´ì œ í˜ë“¤ì–´ìš”... ê·¸ëƒ¥ ì•„ê¹Œ ì¶”ì²œë“œë¦° ê²ƒ ì¤‘ì— í•˜ë‚˜ ë“œì‹œì£ ! ë§ˆì§€ë§‰ì´ì—ìš”!\n\n"
    
    if mismatch_notice and recommended_in_response:
        response_text = f"{mismatch_notice}\n\n{response_text}"

    final_text = f"{retry_prefix}{response_text}"

    # 7. Kakao Response êµ¬ì„±
    return get_final_kakao_response(final_text)


def build_varied_recommendation(choice: Dict, intent_data: Dict, meal_label: str = "ì ì‹¬") -> str:
    """ì²œ ê°€ì§€ ì´ìƒì˜ ì¡°í•©ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ë‹¤ì–‘í•œ ì¶”ì²œ ë©˜íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (Fallbackìš©)."""
    import random
    name = choice.get('name', 'ì¶”ì²œ ë©”ë‰´')
    area = choice.get('area', 'íšŒì‚¬ ê·¼ì²˜')
    
    # 1. ì¸ì‚¬ë§ (12ì¢…)
    headers = [
        "ìŒ... ë§ˆìŠ¤í„°ë‹˜ì„ ìœ„í•´ ì—´ì‹¬íˆ ê³¨ë¼ë´¤ì–´ìš”! âœ¨",
        "ì œ ìƒê°ì—” ì—¬ê¸°ê°€ ì˜¤ëŠ˜ ê¸°ë¶„ê³¼ ë”± ë§ëŠ” ê²ƒ ê°™ì•„ìš”! ğŸ¤—",
        "ê³ ë¯¼ ëì— ê²°ì •í–ˆìŠµë‹ˆë‹¤! ë°”ë¡œ ì—¬ê¸°ì˜ˆìš”. ğŸ±",
        "ì˜¤ëŠ˜ì€ ì™ ì§€ ì´ ë©”ë‰´ê°€ ë§ˆìŠ¤í„°ë‹˜ì„ ë¶€ë¥´ëŠ” ê²ƒ ê°™ë„¤ìš”! ğŸ˜‹",
        "ë©€ë¦¬ ê°€ì§€ ë§ˆì‹œê³  ì—¬ê¸°ì„œ ë“œì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”? ğŸ“",
        "ì‹¤íŒ¨ ì—†ëŠ” ì„ íƒ! ì˜¤ëŠ˜ì€ ì´ ë©”ë‰´ ì–´ë– ì„¸ìš”? ğŸ‘",
        "ë§ˆìŠ¤í„°ë‹˜ì´ ì¢‹ì•„í•˜ì‹¤ ë§Œí•œ ê³³ìœ¼ë¡œ ì°¾ì•„ë´¤ìŠµë‹ˆë‹¤! âœ¨",
        "ê¸°ë¶„ ì „í™˜ì— ë”± ì¢‹ì€ ë©”ë‰´ë¥¼ ë°œê²¬í–ˆì–´ìš”! ğŸŒˆ",
        "ë“ ë“ í•œ í•œ ë¼ë¥¼ ìœ„í•´ ì´ê³³ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤! ğŸ’ª",
        "ì˜¤ëŠ˜ ê°™ì€ ë‚ ì”¨ì—” ì´ëŸ° ë©”ë‰´ê°€ ì§„ë¦¬ì£ ! â›…",
        "ë§›ìˆëŠ” í•œ ë¼! ì—¬ê¸°ë¥¼ ê°•ë ¥ ì¶”ì²œí•©ë‹ˆë‹¤! ğŸ½ï¸",
        "ê³ ë¯¼ í•´ê²°! ì œê°€ ëŒ€ì‹  ê³¨ë¼ë“œë ¸ìŠµë‹ˆë‹¤. ğŸ˜"
    ]
    
    # 2. ì¶”ì²œ ë³¸ë¬¸ (15ì¢…)
    bodies = [
        f"ì˜¤ëŠ˜ {meal_label}ì€ **[{name}]** ì–´ë– ì„¸ìš”? {area}ì— ìˆì–´ì„œ ê°€ê¹ë‹µë‹ˆë‹¤!",
        f"**[{name}]** í•œ ë²ˆ ê°€ë³´ì‹œëŠ” ê±¸ ì¶”ì²œë“œë ¤ìš”! ({area})",
        f"**[{name}]** ì´(ê°€) ì˜¤ëŠ˜ ë©”ë‰´ë¡œ ì•„ì£¼ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”! {area}ì— ìˆë„¤ìš”.",
        f"**[{name}]** ì–´ë–¨ê¹Œìš”? {area} ë¼ì„œ ì ‘ê·¼ì„±ë„ ìµœê³ ì…ë‹ˆë‹¤!",
        f"ì œ ì¶”ì²œì€ ë°”ë¡œ **[{name}]** ì…ë‹ˆë‹¤! ìœ„ì¹˜ëŠ” {area} ì˜ˆìš”.",
        f"ì˜¤ëŠ˜ {meal_label}ì€ **[{name}]** ì–´ë– ì‹ ê°€ìš”? {area} ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤!",
        f"ë§ˆìŠ¤í„°ë‹˜ê»˜ ë”± ë§ëŠ” **[{name}]** ì¶”ì²œë“œë¦½ë‹ˆë‹¤! ({area})",
        f"ê³ ë¯¼ ë§ê³  **[{name}]** ìœ¼ë¡œ ê³ ê³ ! {area} ì— ìˆì–´ìš”.",
        f"**[{name}]** ì—ì„œ ë§›ìˆëŠ” í•œ ë¼ ì–´ë– ì„¸ìš”? {area} ì…ë‹ˆë‹¤!",
        f"ì˜¤ëŠ˜ì€ **[{name}]** ì´(ê°€) ì •ë‹µì¸ ê²ƒ ê°™ë„¤ìš”! ({area})",
        f"**[{name}]** ì¶”ì²œë“œë ¤ìš”! {area} ì— ìˆì–´ì„œ ê¸ˆë°© ê°€ì‹¤ ê±°ì˜ˆìš”.",
        f"í›„íšŒ ì—†ëŠ” ì„ íƒ! **[{name}]** ì¶”ì²œí•©ë‹ˆë‹¤! {area} ì— ìˆì–´ìš”.",
        f"**[{name}]** ì´(ê°€) ë§ˆìŠ¤í„°ë‹˜ì„ ê¸°ë‹¤ë¦¬ê³  ìˆì–´ìš”! ({area})",
        f"ì˜¤ëŠ˜ì€ **[{name}]** ìœ¼ë¡œ ê²°ì •! {area} ì— ìˆë‹µë‹ˆë‹¤.",
        f"ë§ˆìŠ¤í„°ë‹˜ì˜ ë§›ìˆëŠ” í•œ ë¼ë¥¼ ìœ„í•´ **[{name}]** ì¤€ë¹„í•´ë´¤ìŠµë‹ˆë‹¤! ({area})"
    ]
    
    # 3. ë§ˆë¬´ë¦¬ (10ì¢…)
    closers = [
        "ë¶„ëª… ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì‹ì‚¬ê°€ ë˜ì‹¤ ê±°ì˜ˆìš”! ğŸ˜Š",
        "ë§›ìˆê²Œ ë“œì‹œê³  í˜ì°¬ ì˜¤í›„ ë³´ë‚´ì„¸ìš”! ğŸ½ï¸",
        "ë“ ë“ í•˜ê²Œ ë¨¹ê³  ê¸°ë¶„ ì¢‹ê²Œ ì‹œì‘í•´ë´ìš”! ğŸ’ª",
        "ì œê°€ ê³ ë¥¸ ë§Œí¼ ì •ë§ ë§›ìˆì„ ê²ë‹ˆë‹¤! âœ¨",
        "ë§›ìˆëŠ” í•œ ë¼ë¥¼ ì œê°€ ì‘ì›í•©ë‹ˆë‹¤! ğŸ¤—",
        "ì˜¤ëŠ˜ í•˜ë£¨ë„ í™”ì´íŒ…ì´ì—ìš”! ë§›ìˆëŠ” ì‹ì‚¬ ë˜ì„¸ìš”! ğŸŒˆ",
        "ë‹¤ë…€ì˜¤ì‹œë©´ ë¦¬ë·° í•œ ë²ˆ ë“¤ë ¤ì£¼ì„¸ìš”! ğŸ˜‹",
        "ì‹¤íŒ¨ ì—†ëŠ” í•œ ë¼, ì œê°€ ë³´ì¥í•©ë‹ˆë‹¤! ğŸ‘",
        "ì¦ê²ê²Œ ì‹ì‚¬í•˜ì‹œê³  ì˜¤ì„¸ìš”! ğŸ±",
        f"ë§ˆìŠ¤í„°ë‹˜ê»˜ ê¸°ì¨ì„ ì£¼ëŠ” {meal_label} ì‹œê°„ì´ ë˜ê¸¸! âœ¨"
    ]
    
    return f"{random.choice(headers)}\n\n{random.choice(bodies)}\n\n{random.choice(closers)}"

def get_emergency_fallback_response(reason: str, utterance: str = "", user_id: str = "Master", weather: str = None) -> Dict:
    """íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ì„œë²„ ì—ëŸ¬ ì‹œ ì¦‰ì‹œ ë°˜í™˜í•  ì•ˆì „ ì‘ë‹µ (ê¸€ë¡œë²Œ r í™œìš©í•˜ì—¬ ì´ˆê³ ì† ìƒì„±)"""
    import random
    intent_data = {} # [FIX] UnboundLocalError ë°©ì§€
    time_ctx = get_time_context(utterance)
    current_meal_label = time_ctx["current_label"] or "ì ì‹¬"
    requested_meal_label = time_ctx["requested_label"]
    is_late_evening = bool(time_ctx["is_late_evening"])
    meal_label = requested_meal_label or current_meal_label

    try:
        r.refresh_data()
        intent_data = analyze_intent_fallback(utterance)
        intent = intent_data.get("intent")
        logger.warning(f"ğŸš¨ Fallback Logic | Utterance: '{utterance}' | Detected Intent: '{intent}'")
        
        if weather: intent_data["weather"] = weather
        
        # [NEW] 'ì´ìœ (explain)' ë¬¼ì–´ë´¤ëŠ”ë° ë¹„ìƒ ëª¨ë“œì¸ ê²½ìš°
        if intent == "explain":
            last_rec = session_manager.get_last_recommendation(user_id)
            if last_rec:
                try:
                    # ë§ˆì§€ë§‰ ì¶”ì²œì´ ìˆìœ¼ë©´ ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì¤Œ
                    explanation = generate_explanation_fallback(last_rec, weather=weather, mood=intent_data.get("mood"))
                    # [ë‹¤ì–‘í™”] ì„¤ëª… ì•ì— ë¶™ëŠ” ë©˜íŠ¸ë„ ëœë¤í™”
                    prefixes = [
                        "ì•„, ê·¸ ë©”ë‰´ë¥¼ ê³ ë¥¸ ì´ìœ ìš”? ë°”ë¡œ ì´ê±°ì˜ˆìš”! ğŸ‘‡\n\n",
                        "ì œê°€ ì™œ ì—¬ê¸¸ ê³¨ëëŠ”ì§€ ê¶ê¸ˆí•˜ì‹œì£ ? âœ¨\n\n",
                        "ë§ˆìŠ¤í„°ë‹˜ì„ ìœ„í•´ ê³ ë¯¼í•œ ê²°ê³¼ì…ë‹ˆë‹¤! ğŸ‘\n\n",
                        "ì´ëŸ° íŠ¹ë³„í•œ ì´ìœ ê°€ ìˆì—ˆë‹µë‹ˆë‹¤. ğŸ˜Š\n\n"
                    ]
                    
                    final_text = f"{random.choice(prefixes)}{explanation}"
                    
                    # [DEFENSIVE] 2001 ì—ëŸ¬ ë°©ì§€ (ê¸¸ì´/ë‚´ìš© ì²´í¬) - ì¹´ì¹´ì˜¤ ì œí•œ ì¤€ìˆ˜
                    if not final_text or len(final_text) > 400:
                        logger.warning(f"âš ï¸ Text too long or empty ({len(final_text)}): {final_text[:50]}...")
                        final_text = f"'{last_rec.get('name')}' ê°€ë³´ì‹œë©´ ì ˆëŒ€ í›„íšŒ ì•ˆ í•˜ì‹¤ ê±°ì˜ˆìš”! ë¯¿ê³  ë“œì…”ë³´ì„¸ìš”. ğŸ‘"
                        
                    return get_final_kakao_response(final_text)
                    
                except Exception as ex:
                    logger.warning(f"ğŸš¨ Explain Gen Failed: {ex}")
                    return get_final_kakao_response(f"'{last_rec.get('name')}' ì •ë§ ë§›ìˆëŠ” ê³³ì´ë¼ ì¶”ì²œë“œë ¸ì–´ìš”! ğŸ˜Š")
            else:
                # ì¶”ì²œ ë‚´ì—­ì´ ì—†ìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œìœ¼ë¡œ ìœ ë„
                return get_final_kakao_response("ì•„ì§ ì œê°€ ì•„ë¬´ê²ƒë„ ì¶”ì²œë“œë¦¬ì§€ ì•Šì•˜ë„¤ìš”! ğŸ˜Š ë§›ìˆëŠ” ë©”ë‰´ í•˜ë‚˜ ê³¨ë¼ë“œë¦´ê¹Œìš”?")

        # ì¶”ì²œ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ì§€ë§Œ ë©˜íŠ¸ ìƒì„±ì€ build_varied_recommendation ì‚¬ìš©)
        fallback_menu = r.recommend(
            weather=intent_data.get("weather"),
            cuisine_filters=intent_data.get("cuisine_filters"),
            mood=intent_data.get("mood"),
            tag_filters=intent_data.get("tag_filters"),
            meal_label=meal_label,
            is_late_evening=is_late_evening,
        )
    except:
        fallback_menu = None

    if not fallback_menu:
        fallback_menu = random.choice(r.menus) if r.menus else {"name": "íšŒì‚¬ ê·¼ì²˜ ë§›ì§‘", "area": "ê·¼ì²˜"}

    # [í•µì‹¬] ì¡°í•©í˜• ì—”ì§„ìœ¼ë¡œ ë©˜íŠ¸ ë‹¤ì–‘í™”
    message = build_varied_recommendation(fallback_menu, intent_data, meal_label=meal_label)
    
    # [FIX] ì„¸ì…˜ì— ì¶”ì²œ ì´ë ¥ì„ ì €ì¥í•´ì•¼ "ì´ìœ ëŠ”?" ì§ˆë¬¸ì— ëŒ€ë‹µí•  ìˆ˜ ìˆìŒ
    try:
        r.history_mgr.save_history(user_id, fallback_menu['name']) # ì¥ê¸° ê¸°ì–µ (ì¤‘ë³µ ë°©ì§€)
        session_manager.set_last_recommendation(user_id, fallback_menu) # ë‹¨ê¸° ê¸°ì–µ (ë¬¸ë§¥ ëŒ€í™”)
    except:
        pass
        
    return get_final_kakao_response(message)


def get_help_response() -> Dict:
    """ë„ì›€ë§ ì‘ë‹µ (ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ë¶„ë¦¬)"""
    text = (
        "ğŸ¤– **DDMC ì ì‹¬ ì¶”ì²œ ë´‡ ì‚¬ìš©ë²•**\n\n"
        "1ï¸âƒ£ **ë©”ë‰´ ì¶”ì²œ**: \"ì ì‹¬ ì¶”ì²œ\", \"ë¹„ ì˜¤ëŠ”ë° ë­ ë¨¹ì§€\", \"ëœë¤\"\n"
        "2ï¸âƒ£ **ì´ìœ /ì •ë³´**: \"ì´ìœ ëŠ”?\", \"ì–´ë””ì•¼?\", \"ë‚ ì”¨ ì–´ë•Œ\"\n"
        "3ï¸âƒ£ **ê¸°ë¶„ ë§ì¶¤**: \"í™”ë‚¬ì„ ë•Œ ë§¤ìš´ ê±°\", \"ë‹¤ì´ì–´íŠ¸ ë©”ë‰´\""
    )
    return get_final_kakao_response(text)


def get_final_kakao_response(text: str) -> Dict:
    """ìµœì¢… ì¹´ì¹´ì˜¤ ì‘ë‹µ í¬ë§·íŒ…"""
    return {
        "version": "2.0",
        "template": {
            "outputs": [{"simpleText": {"text": text}}],
            "quickReplies": [
                {"label": "ğŸ² ëœë¤ ì¶”ì²œ", "action": "message", "messageText": "ëœë¤ ì¶”ì²œí•´ì¤˜"},
                {"label": "â›… ë‚ ì”¨ ë§ì¶¤", "action": "message", "messageText": "ë‚ ì”¨ì— ë§ê²Œ ì¶”ì²œí•´ì¤˜"},
                {"label": "â“ ë„ì›€ë§", "action": "message", "messageText": "ë„ì›€ë§"},
            ],
        },
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run("bot_server:app", host="0.0.0.0", port=8000, reload=False)
